# general
gpu_id: '0'                     # (str) The id of GPU device(s).
worker: 0                       # (int) The number of workers processing the data.
use_gpu: True                   # (bool) Whether or not to use GPU.
seed: 2020                      # (int) Random seed.
state: INFO                     # (str) Logging level.
reproducibility: True           # (bool) Whether or not to make results reproducible.
data_path: 'dataset/'           # (str) The path of input dataset.
checkpoint_dir: 'saved'         # (str) The path to save checkpoint file.
show_progress: True             # (bool) Whether or not to show the progress bar of every epoch. 
save_dataset: False             # (bool) Whether or not to save filtered dataset.
dataset_save_path: ~            # (str) The path of saved dataset.
save_dataloaders: False         # (bool) Whether or not save split dataloaders.
dataloaders_save_path: ~        # (str) The path of saved dataloaders.
log_wandb: False                # (bool) Whether or not to use Weights & Biases(W&B).
wandb_project: 'recbole'        # (str) The project to conduct experiments in W&B.
shuffle: True                   # (bool) Whether or not to shuffle the training data before each epoch.

# training settings
train_epochs: ["BOTH:300"]
train_batch_size: 2048
learner: adam
learning_rate: 0.001
neg_sampling:
  uniform: 1
eval_step: 1
stopping_step: 10
clip_grad_norm: ~
# clip_grad_norm:  {'max_norm': 5, 'norm_type': 2}
weight_decay: 0.0
loss_decimal_place: 4
require_pow: False

# evaluation settings
eval_args:                      # (dict) 4 keys: group_by, order, split, and mode
  split: {'RS':[0.8,0.1,0.1]}   # (dict) The splitting strategy ranging in ['RS','LS'].
  split_valid: {'RS':[0.8,0.2]}
  group_by: user                # (str) The grouping strategy ranging in ['user', 'none'].
  order: RO                     # (str) The ordering strategy ranging in ['RO', 'TO'].
  mode:                         # (str) The evaluation mode ranging in ['full','unixxx','popxxx','labeled'].
    valid: full       
    test: full
repeatable: False               # (bool) Whether to evaluate results with a repeatable recommendation scene. 
metrics: ["Recall","MRR","NDCG","Hit","Precision"]  # (list or str) Evaluation metrics.
topk: [10]                      # (list or int or None) The value of k for topk evaluation metrics.
valid_metric: MRR@10            # (str) The evaluation metric for early stopping. 
valid_metric_bigger: True       # (bool) Whether to take a bigger valid metric value as a better result.
eval_batch_size: 4096           # (int) The evaluation batch size.
metric_decimal_place: 4         # (int) The decimal place of metric scores.